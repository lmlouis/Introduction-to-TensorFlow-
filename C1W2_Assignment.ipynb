{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2s0EJ5Fy4u2"
   },
   "source": [
    "# Week 2: Implementing Callbacks in TensorFlow using the MNIST Dataset\n",
    "Dans ce cours, vous avez appris à effectuer une classification à l'aide de Fashion MNIST, un ensemble de données contenant des vêtements. Il existe un autre jeu de données similaire, appelé MNIST, qui contient des éléments d'écriture manuscrite - les chiffres de 0 à 9.\n",
    "\n",
    "Ecrivez un classificateur MNIST qui s'entraîne à 99% de précision et s'arrête une fois ce seuil atteint. Dans le cours, vous avez vu comment cela était fait pour le loss, mais ici vous utiliserez accuracy à la place.\n",
    "\n",
    "Quelques notes :\n",
    "\n",
    "1. Votre réseau doit réussir en moins de 9 époques (epochs).\n",
    "2. Lorsqu'il atteint 99% ou plus, il doit imprimer la chaîne \"Reached 99% accuracy so cancelling training !\" et arrêter l'entraînement.\n",
    "3. Si vous ajoutez des variables supplémentaires, assurez-vous d'utiliser les mêmes noms que ceux utilisés dans la classe. Ceci est important pour les signatures de fonction (les paramètres et les noms) des callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and inspect the data\n",
    "\n",
    "Commencez par charger les données. Deux ou trois choses à noter :\n",
    "\n",
    "- Le fichier `mnist.npz` est déjà inclus dans l'espace de travail actuel sous le dossier `data` . Par défaut, le `load_data` de Keras accepte un chemin relatif à `~/.keras/datasets` mais dans ce cas, il est stocké ailleurs, ce qui fait que vous devez spécifier le chemin complet.\n",
    "\n",
    "- `load_data` renvoie les ensembles de formation et de test sous la forme de tuples `(x_train, y_train), (x_test, y_test)` mais dans cet exercice, vous n'aurez besoin que de la rame, vous pouvez donc ignorer le deuxième tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "# Get current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Append data/mnist.npz to the previous path to get the full path\n",
    "data_path = os.path.join(current_dir, \"data/mnist.npz\")\n",
    "\n",
    "# Discard test set\n",
    "(x_train, y_train), _ = tf.keras.datasets.mnist.load_data(path=data_path)\n",
    "        \n",
    "# Normalize pixel values\n",
    "x_train = x_train / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, regardez la forme des données de formation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 60000 examples with shape (28, 28)\n"
     ]
    }
   ],
   "source": [
    "data_shape = x_train.shape\n",
    "\n",
    "print(f\"There are {data_shape[0]} examples with shape ({data_shape[1]}, {data_shape[2]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining your callback\n",
    "\n",
    "Il est maintenant temps de créer votre propre callback. Pour cela, il faut compléter le `myCallback` class et le `on_epoch_end` method dans la cellule ci-dessous. Si vous avez besoin de conseils sur la façon de procéder, consultez le site suivant [link](https://www.tensorflow.org/guide/keras/custom_callback)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED CLASS: myCallback\n",
    "### START CODE HERE\n",
    "\n",
    "# Remember to inherit from the correct class\n",
    "class myCallback(keras.callbacks.Callback):\n",
    "        # Define the correct function signature for on_epoch_end\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            if logs.get('accuracy') is not None and logs.get('accuracy') > 0.99:\n",
    "                print(\"\\nReached 99% accuracy so cancelling training!\") \n",
    "                \n",
    "                # Stop training once the above condition is met\n",
    "                self.model.stop_training = True\n",
    "\n",
    "### END CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and train your model\n",
    "\n",
    "Maintenant que vous avez défini votre callback, il est temps de compléter le processus d'intégration. `train_mnist` fonction ci-dessous. \n",
    "\n",
    "**Vous devez configurer votre modèle pour qu'il s'entraîne pendant 10 époques et la fonction de rappel doit se déclencher avant la 9e époque pour que vous réussissiez cette tâche.**\n",
    "\n",
    "**Indice:**\n",
    "- N'hésitez pas à essayer l'architecture du réseau neuronal qui vous convient, mais si vous avez besoin d'une aide supplémentaire, vous pouvez consulter une architecture qui fonctionne plutôt bien à la fin de ce notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "rEHcB3kqyHZ6",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: train_mnist\n",
    "def train_mnist(x_train, y_train):\n",
    "\n",
    "    ### START CODE HERE\n",
    "    \n",
    "    # Instantiate the callback class\n",
    "    callbacks = myCallback()\n",
    "    \n",
    "    # Define the model\n",
    "    model = tf.keras.models.Sequential([ \n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ]) \n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='sparse_categorical_crossentropy', \n",
    "                  metrics=['accuracy']) \n",
    "    \n",
    "    # Fit the model for 10 epochs adding the callbacks\n",
    "    # and save the training history\n",
    "    history = model.fit(x_train, y_train, epochs=10, callbacks=[callbacks])\n",
    "\n",
    "    ### END CODE HERE\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the `train_mnist` passing in the appropiate parameters to get the training history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "sFgpwbGly4u4",
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1999 - accuracy: 0.9413\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0805 - accuracy: 0.9751\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0506 - accuracy: 0.9838\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0353 - accuracy: 0.9892\n",
      "Epoch 5/10\n",
      "1870/1875 [============================>.] - ETA: 0s - loss: 0.0280 - accuracy: 0.9907\n",
      "Reached 99% accuracy so cancelling training!\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0280 - accuracy: 0.9908\n"
     ]
    }
   ],
   "source": [
    "hist = train_mnist(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vous voyez le message `Reached 99% accuracy so cancelling training!` s'affiche après moins de 9 époques, cela signifie que votre callback a fonctionné comme prévu. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need more help?\n",
    "\n",
    "Exécutez la cellule suivante pour voir une architecture qui fonctionne bien pour le problème en question :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   - A Flatten layer that receives inputs with the same shape as the images\n",
      "   - A Dense layer with 512 units and ReLU activation function\n",
      "   - A Dense layer with 10 units and softmax activation function\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# WE STRONGLY RECOMMEND YOU TO TRY YOUR OWN ARCHITECTURES FIRST\n",
    "# AND ONLY RUN THIS CELL IF YOU WISH TO SEE AN ANSWER\n",
    "\n",
    "import base64\n",
    "\n",
    "encoded_answer = \"CiAgIC0gQSBGbGF0dGVuIGxheWVyIHRoYXQgcmVjZWl2ZXMgaW5wdXRzIHdpdGggdGhlIHNhbWUgc2hhcGUgYXMgdGhlIGltYWdlcwogICAtIEEgRGVuc2UgbGF5ZXIgd2l0aCA1MTIgdW5pdHMgYW5kIFJlTFUgYWN0aXZhdGlvbiBmdW5jdGlvbgogICAtIEEgRGVuc2UgbGF5ZXIgd2l0aCAxMCB1bml0cyBhbmQgc29mdG1heCBhY3RpdmF0aW9uIGZ1bmN0aW9uCg==\"\n",
    "encoded_answer = encoded_answer.encode('ascii')\n",
    "answer = base64.b64decode(encoded_answer)\n",
    "answer = answer.decode('ascii')\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations on finishing this week's assignment!**\n",
    "\n",
    "You have successfully implemented a callback that gives you more control over the training loop for your model. Nice job!\n",
    "\n",
    "**Keep it up!**"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
